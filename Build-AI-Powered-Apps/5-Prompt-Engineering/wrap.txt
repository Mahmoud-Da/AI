*** 1- What is Prompt Engineering ***
---

## Prompt Engineering: Core Concepts

### 1. What Prompt Engineering Is

* Prompt engineering is the skill of writing better instructions for language models.
* It is not complex or mystical; it simply means communicating more clearly with the model.
* When using tools like ChatGPT or integrating models such as GPT-4 into applications, we do not write code for the model.
* Instead, we provide **text prompts**, and the model predicts the next output based on those prompts.

---

### 2. Why Prompt Engineering Matters

* Small changes in how a prompt is written can lead to dramatically different results.
* The model behaves like a very intelligent assistant that:

  * Does exactly what you ask.
  * Does nothing beyond what you specify.
* If the prompt is vague, the model must guess.
* If the prompt is clear and specific, the model delivers more accurate and useful results.

---

### 3. Example: Vague vs. Clear Prompts

**Vague Prompt**

* “Summarize this text.”
* Problems:

  * No indication of length.
  * No target audience.
  * No format or tone specified.

**Improved Prompt**

* “Summarize the following product reviews in three short bullet points. Focus on common themes and use simple language.”
* Improvements:

  * Specifies output length.
  * Defines formatting.
  * Clarifies tone and focus.

This demonstrates how structure and clarity significantly improve results.

---

### 4. The Essence of Prompt Engineering

* Prompt engineering is about learning how to “talk” to the model effectively.
* Good prompts:

  * Reduce ambiguity.
  * Provide structure.
  * Guide tone, format, and intent.
* Writing good prompts is a skill, similar to writing good code.
* It improves with practice.

---

### 5. Prompt Engineering for Developers

* Prompt engineering is not limited to marketing or copywriting.
* Developers use it constantly, including when building:

  * Chatbots
  * Summarization tools
  * Content generators
  * Any application that interacts with a language model
* Even for code generation:

  * The quality of generated code depends heavily on the quality of the prompt.

---

### 6. Benefits in Real Applications

* Helps reduce ambiguity in outputs.
* Improves consistency and reliability.
* Allows developers to shape outputs that are directly used inside applications.
* Makes model behavior more predictable and controllable.

---

### 7. What Comes Next

* Upcoming lessons will cover:

  * Core principles of effective prompts
  * Practical techniques to improve prompt quality
* The goal is to make prompts more effective and more aligned with real-world use cases.

---

*** 2- Anatomy of a Good Prompt ***
---

## The Anatomy of a Good Prompt

### 1. Overview

* High-quality, consistent prompts usually follow a simple structure.
* A well-designed prompt typically includes:

  1. An **instruction**
  2. **Context**
  3. A **desired output format**
* Each part plays a role in shaping how the model responds.

---

### 2. Instruction: Telling the Model What to Do

* The instruction is the core action you want the model to perform.
* Example (basic):

  * “Summarize the following product reviews.”
* Improved version:

  * “Summarize the following reviews in three short bullet points using simple language.”
* Improvements in the second version:

  * Specifies the task (summarize).
  * Defines the output length.
  * Specifies the format (bullet points).
  * Sets expectations for tone and complexity.
* Small refinements to instructions can significantly improve output quality.

---

### 3. Context: Giving Background Information

* Context provides supporting information that helps the model understand the task better.
* Context can include:

  * A role for the model to assume.
  * Text or data to analyze.
  * Background information relevant to the task.
* Example:

  * “You are a senior software engineer. Read the code snippet below and explain it in plain English.”
* Clear and detailed context:

  * Guides the tone and focus of the response.
  * Improves accuracy and relevance.
* In general, more relevant context leads to better results.

---

### 4. Output Format: Defining the Shape of the Response

* Output format is often overlooked but is especially important in development workflows.
* The prompt should clearly specify the expected structure of the output.
* Common formats include:

  * Bullet lists
  * Tables
  * Paragraphs
  * Structured data such as JSON
* Example:

  * “Label this message as spam or not spam. Return the result as JSON with a single key called `label`.”
* This approach tells the model:

  * What decision to make.
  * Exactly how the result should be returned.

---

### 5. Combining Instruction, Context, and Format

* A strong prompt combines all three components into a single, coherent request.
* Example:

  * “You are a helpful support agent. Summarize the following customer reviews in two to three bullet points. Focus on pain points related to the login experience.”
* This prompt specifies:

  * **Role**: Helpful support agent
  * **Task**: Summarization
  * **Focus**: Login-related pain points
  * **Format**: Bullet points in plain text

---

### 6. Key Takeaways

* Clear instructions reduce ambiguity.
* Relevant context improves tone, focus, and accuracy.
* Explicit output formats increase consistency and make results easier to use in applications.
* Combining these elements leads to reliable, production-ready prompts.

---

### 7. What’s Next

* The next lesson will explore how to provide context more effectively and in greater detail.

*** 3- Providing Context ***
---

## Providing Effective Context in Prompts

### 1. Recap: Prompt Structure

* So far, prompts have been structured around:

  * Clear instructions
  * Context (often with examples)
  * A desired output format
* In this lesson, the focus is specifically on **context**, which becomes critical when building real applications with LLMs.

---

### 2. Why Context Matters in Real Applications

* A basic chatbot can answer questions, but without context it is just a generic wrapper around ChatGPT.
* Without additional information, the model:

  * Knows nothing about your business, product, or customers
  * Produces general-purpose responses
* Adding context transforms the model into something useful and valuable.
* Context allows the model to:

  * Answer questions accurately
  * Reflect your product’s voice
  * Reduce user effort and navigation

---

### 3. Example: Improving a Chatbot with Context

* Consider a chatbot for a theme park.
* Without context:

  * Users receive generic answers
  * They still need to browse multiple pages for basic information
* With context (rides, hours, ticket policies):

  * The chatbot can answer real customer questions directly
  * Users can quickly learn things like:

    * Closing times
    * Which rides are suitable for toddlers
* This illustrates the practical power of context.

---

### 4. Assigning a Role to the Model

* One simple way to provide context is by assigning a role.
* Examples:

  * “You are a senior backend engineer. Explain the code below to a junior developer.”
  * “You are a customer support agent. Respond in a polite and empathetic tone.”
* Role assignment:

  * Does not add new capabilities
  * Strongly influences tone, structure, and focus
  * Immediately changes how the model communicates

---

### 5. Supplying Background Information

* Background information is useful when the model must follow specific rules or facts.
* Examples:

  * Refund policies
  * Business rules
  * Product details
* Example prompt structure:

  * “You are a customer support assistant. Here is our refund policy. Now answer the customer’s question.”
* This ensures responses are aligned with real constraints and knowledge.

---

### 6. Defining the Audience

* Specifying the audience helps control tone and complexity.
* Examples:

  * “Explain this topic to a non-technical user.”
  * “Write this summary for a high school student.”
* This helps the model:

  * Adjust vocabulary
  * Simplify or deepen explanations
  * Match user expectations

---

### 7. Controlling Tone and Style

* Tone is especially important in customer-facing features.
* You can specify tone directly in the prompt.
* Examples:

  * “Respond in a friendly, conversational tone. Avoid sounding formal or robotic.”
  * “Use professional, empathetic language like a calm support representative helping a frustrated customer.”
* These instructions make interactions feel more human and natural.

---

### 8. Including Reference Material

* Often, the model needs source material to work with, such as:

  * Product descriptions
  * Customer reviews
  * Emails or transcripts
* Best practice:

  * Visually separate instructions from reference content
* Common separators:

  * Triple dashes
  * Triple quotes
  * XML-style tags
* The key principle is clarity, not the specific format.

---

### 9. Key Takeaways on Context

* Providing context does not mean writing long or repetitive prompts.
* It means giving the model exactly what it needs to produce:

  * Accurate results
  * Relevant answers
  * Useful, application-ready output
* Context bridges the gap between:

  * Generic responses
  * Real, functional product behavior

---

### 10. What’s Next

* The next lesson will focus on controlling the structure of the model’s output.
* This includes returning:

  * Structured data
  * Lists
  * Formats that applications can reliably consume

*** 4- Controlling the Output Format ***
---

## Controlling Output Format in Prompts

### 1. Why Output Format Matters

* In real applications, output format is just as important as content.
* We need to control:

  * Whether the response is plain text, a list, or structured data
  * How the output can be consumed by code
* At this point, prompt engineering starts to resemble programming.

---

### 2. Default Model Behavior

* By default, models return plain text in paragraph form.
* This is often sufficient for readability and natural responses.
* However, even with plain text, we should control:

  * Length
  * Completeness
  * Cost

---

### 3. Controlling Length and Cost

* If length is not specified, responses may:

  * Be longer than necessary
  * Exceed output token limits
  * Increase costs
* Best practices include specifying:

  * Sentence count
  * Token limits
* Examples:

  * “Summarize this in two short sentences.”
  * “Summarize this in under 100 tokens.”
* Additional guidance:

  * Ask the model to ensure the response is complete and does not end mid-sentence.

---

### 4. Using Markdown for Structured Text

* Markdown allows for simple formatting such as:

  * Bold text
  * Italics
  * Bullet points
* Useful for:

  * Summaries
  * Lists
  * Readable UI output
* Example:

  * “Summarize this review in two bullet points using markdown. Highlight important details in bold.”

---

### 5. Returning Simple Structured Formats

* For lightweight structure, formats like comma-separated lists are useful.
* Example use case:

  * Extracting keywords or tags
* Example prompt:

  * “Extract three keywords that describe this article. Return them as a comma-separated list in lowercase.”
* Greater specificity leads to more consistent output.

---

### 6. Requesting Structured Data with JSON

* JSON is ideal when output must be consumed directly by code.
* Example use case:

  * Extracting product names and prices from text
* Example prompt:

  * “From the paragraph below, extract all product names and their prices. Return a valid JSON array of objects. Each object should include a `name` (string) and a `price` (number without currency symbols).”

---

### 7. Enforcing Strict JSON Output

* Models may add explanations or extra text unless instructed otherwise.
* To prevent this, add explicit constraints:

  * “Only return valid JSON.”
  * “No explanation or additional text.”
* This ensures the output can be safely parsed and used in applications.

---

### 8. Key Takeaways

* Always specify the desired output format.
* Control response length to improve UX and reduce cost.
* Use markdown for human-readable formatting.
* Use JSON when output needs to integrate directly with code.
* Clear formatting instructions lead to predictable, reliable results.

---

### 9. What’s Next

* The next lesson will focus on providing examples in prompts.
* This technique helps models learn patterns and match a desired style or structure more consistently.


*** 5- Providing Examples ***
---

## Common Prompting Strategies

### 1. Overview

* There are three widely used prompting strategies:

  * **Zero-shot prompting**
  * **One-shot prompting**
  * **Few-shot prompting**
* These strategies differ in how many examples are provided to guide the model’s behavior.

---

### 2. Zero-Shot Prompting

* Zero-shot prompting provides:

  * A task description
  * No examples
* The model is expected to infer how to perform the task.

**Example**

* “Classify product reviews as positive, neutral, or negative.”

**Why This Works**

* Sentiment analysis is a well-known NLP task.
* Large language models have seen many similar examples during training.
* The categories are intuitive and easy to understand.

**Best Practices**

* Always constrain the possible outputs.
* Explicitly state allowed values (e.g., positive, neutral, negative).
* Without constraints, the model may return vague or verbose responses that are difficult to use in code.

---

### 3. Limitations of Zero-Shot Prompting

* Zero-shot prompts may fail when:

  * A specific output structure is required
  * Consistency is critical
* Example issue:

  * Asking the model to “turn this review into a JSON object” without guidance
  * The model may invent its own schema or produce inconsistent output

---

### 4. One-Shot Prompting

* One-shot prompting provides:

  * A task description
  * One example showing the desired output
* This single example teaches the model:

  * The expected structure
  * The key names
  * The type of values to return

**Example Use Case**

* Returning sentiment as a structured JSON object with a specific key (e.g., `sentiment`).

**When to Use**

* The task is relatively simple
* The output format is clear and constrained
* One example is enough to demonstrate the pattern

---

### 5. Few-Shot Prompting

* Few-shot prompting provides:

  * Multiple examples (typically three to five)
* Used when tasks are more complex or ambiguous.

**Example Use Case**

* Analyzing support messages and returning structured data with multiple fields:

  * `intent`
  * `urgency`
  * `mentions_order`

**Why Few-Shot Is Needed**

* The model must learn:

  * Valid values for each field
  * How to infer urgency
  * When to set boolean flags to true or false
* One example is insufficient to cover all decision rules.

---

### 6. How Many Examples to Use

* There is no fixed rule for the number of examples.
* General guideline:

  * Three to five high-quality examples work well in most cases
* More complex tasks may require more examples.

---

### 7. Characteristics of Good Examples

* Examples should be:

  * Clear and unambiguous
  * Well formatted and consistent in structure
  * Diverse, covering different scenarios
  * Inclusive of edge cases
* High-quality examples lead to more reliable and predictable outputs.

---

### 8. Summary

* **Zero-shot**: No examples; relies on model’s prior knowledge
* **One-shot**: One example; teaches structure and format
* **Few-shot**: Multiple examples; teaches rules, variations, and edge cases

---

### 9. What’s Next

* The next lesson will focus on handling errors and edge cases in model outputs.

*** 6- Handling Errors and Edge Cases ***
---

## Prompt Reliability and Handling Edge Cases

### Core Idea

Prompting should be treated like writing a well-tested function.
A prompt that works with ideal input is not enough; it must also behave correctly when the input is bad, incomplete, or unexpected.

---

### Analogy: Prompts vs Functions

* When writing a function:

  * You test the happy path (valid input).
  * You also test how it handles invalid or unexpected data.
* Prompting follows the same principle:

  * Even if a prompt works with clean input, it must be tested against edge cases.

---

### Why Edge Case Handling Is Necessary

* By default, language models try to answer even when the input is:

  * Empty
  * Vague
  * Incorrect
  * Total nonsense
* This can lead to misleading or low-quality output.
* It is the prompt designer’s responsibility to define boundaries.

---

### Technique 1: Explicit Error Handling

You can instruct the model to return an error instead of guessing.

Examples:

* If the input is empty or not a valid product review, return a specific error object.
* If the input contains fewer than a certain number of words (e.g., fewer than 5), return a different error object.

Key point:

* The exact rules depend on what you are building and your application’s requirements.

---

### Applicability Across Tasks

The same edge case principles apply to all types of tasks, including:

* Summarization
* Data extraction
* Translation
* Content generation

In every case, the prompt should define what the model should do when input is missing or invalid.

---

### Technique 2: Asking Clarifying Questions

* Instead of returning an error, the model can ask for clarification.
* This approach makes sense mainly in chatbot scenarios.

Example instruction:

* If the user’s request is vague or lacks necessary detail, ask a clarifying question instead of guessing.

---

### Prompt Testing Strategy

Always test prompts with a variety of edge cases, such as:

* Empty input
* Input containing only whitespace
* One or two random words
* Gibberish text
* Extremely long input
* Input missing key details

---

### Iteration and Refinement

* Observe how the model responds to edge cases.
* If the output is incorrect or unreliable:

  * Refine the prompt.
  * Add clearer constraints or instructions.
* Repeat testing until the behavior is stable and predictable.

---

### What’s Next

* The next lesson focuses on:

  * Why language models sometimes make things up
  * Techniques to reduce hallucinations and unreliable output

---

*** 7- Reducing Hallucinations ***
---

## Hallucinations in Large Language Models

### Definition

* **Hallucination** refers to situations where a language model generates information that sounds plausible but is not true.
* This behavior is not malicious; it is a natural outcome of how language models work.

---

### Why Hallucinations Happen

* Language models do not “know” facts.
* They do not query databases or verify information.
* Instead, they predict the next piece of text based on patterns learned during training.
* Hallucinations are more likely when:

  * Questions are vague or open-ended
  * Prompts lack sufficient context or constraints
  * The model is forced to fill in missing information

---

### Strategy 1: Ground the Model with Facts

* If accuracy matters, include the relevant data directly in the prompt.
* Do not expect the model to recall policies or rules correctly on its own.

Example concept:

* Provide the refund policy first.
* Then ask the model to answer the customer’s question based on that policy.

Key idea:

* This approach is called **grounding**.
* The response is anchored to real, provided information.

---

### Strategy 2: Define What to Do When the Model Does Not Know

* Sometimes the answer is unavailable or the input is unclear.
* In these cases, it is better for the model to admit uncertainty than to guess.

Prompt instruction example:

* If the answer is unknown or unclear, respond with a statement indicating that the information is not available.
* Explicitly tell the model not to guess or invent an answer.

Principle:

* Silence or refusal is better than fabricated content.

---

### Strategy 3: Limit the Model’s Scope

* Hallucinations often occur when the model answers questions outside its intended domain.
* Without constraints, the model will attempt to answer anything confidently.

Example scenario:

* A chatbot built for a theme park may receive unrelated questions.
* Without guidance, the model will still try to respond.

Solution:

* Clearly define the model’s role and allowed topics.
* Specify how it should respond to out-of-scope questions.

Result:

* The model stays focused on relevant topics and avoids off-topic hallucinations.

---

### Post-Processing and Safety Measures

* Even with strong prompts, hallucinations can still occur.
* General-purpose models are especially prone to this.

Best practices:

* Validate structured outputs such as JSON using a schema or validation library.
* Treat model output the same way as untrusted API input.
* Avoid using AI outputs directly for critical decisions without human review.
* Log and monitor outputs to detect unusual or incorrect behavior.

---

### Key Takeaways

* Language models are not fact-checkers; they are text prediction systems.
* Reliable output requires reliable input.
* Hallucinations do not mean the model is broken.
* They indicate that clearer instructions, better data, and stronger constraints are needed.

---

*** 8- Refining Prompts ***
---

## Building and Refining a Prompt: Theme Park Assistant Example

### Goal of the Lesson

* Apply previously learned prompting concepts in practice.
* Build and iteratively refine a real prompt for a theme park customer support assistant.
* Use OpenAI’s Playground to test and improve the prompt.
* Prepare the prompt to be integrated into an application in the next lesson.

---

### Step 1: Start with a Simple Question

* Initial question: “What time does the park close?”
* Without context, the model asks for clarification because it has no information about:

  * The park
  * The business
  * Operating hours

Prompt
-------------------code----------------------
What time does the park close?
-------------------code----------------------

LLM Answer
-------------------code----------------------
Could you please specify which park you are referring to?
-------------------code----------------------
Key insight:

* By default, the model behaves like a general-purpose chatbot with no domain knowledge.

---

### Step 2: Provide Basic Context

* Add an instruction defining the model’s role and business details:

  * The model is a customer support agent
  * The theme park name is Wonderworld
  * Opening hours are clearly specified by day range

instructions
-------------------code----------------------
You are a customer support agent for a theme park named Wonderworld.

Wonderworld opening hours:
- Monday to Thursday: 9:00 AM to 5:00 PM
- Friday to Sunday: 9:00 AM to 9:00 PM
-------------------code----------------------

Prompt
-------------------code----------------------
What time does the park close?
-------------------code----------------------

LLM Answer
-------------------code----------------------
Wonderworld closes at 5:00 PM from Monday to Thursday and at 9:00 PM from Friday to Sunday.
-------------------code----------------------

Result:

* The model can now correctly answer general closing-time questions.

---

### Step 3: Refine for User Intent

* User intent: “What time does the park close today?”
* Problem:

  * The model does not know the current date or day.
  * It asks the user to specify the day, which feels unnatural.

instructions
-------------------code----------------------
You are a customer support agent for a theme park named Wonderworld.

Wonderworld opening hours:
- Monday to Thursday: 9:00 AM to 5:00 PM
- Friday to Sunday: 9:00 AM to 9:00 PM
-------------------code----------------------

Prompt
-------------------code----------------------
What time does the park close today?
-------------------code----------------------

LLM Answer
-------------------code----------------------
Could you please specify which park you are referring to?
-------------------code----------------------
Key limitation:

* LLMs do not have access to real-time date and time unless provided.

---

### Step 4: Inject the Current Date

* Add the current date and day directly into the prompt.
* Initially hard-coded for testing.
* In a real application, this value should be inserted dynamically.

instructions
-------------------code----------------------
You are a customer support agent for a theme park named Wonderworld.

Wonderworld opening hours:
- Monday to Thursday: 9:00 AM to 5:00 PM
- Friday to Sunday: 9:00 AM to 9:00 PM

Today is Thursday, July 17.
-------------------code----------------------

Prompt
-------------------code----------------------
What time does the park close today?
-------------------code----------------------


LLM Answer
-------------------code----------------------
Today is Thursday, July 17. Wonderworld closes at 5:00 PM today.
-------------------code----------------------

Result:

* The model correctly answers the question based on the provided date.

---

### Step 5: Improve Naturalness of Responses

* Issue:

  * The model repeats the full date in its response.
* Refinement:

  * Add an instruction telling the model not to repeat today’s date.

instructions
-------------------code----------------------
You are a customer support agent for a theme park named Wonderworld.

Wonderworld opening hours:
- Monday to Thursday: 9:00 AM to 5:00 PM
- Friday to Sunday: 9:00 AM to 9:00 PM

Today is Thursday, July 17.

Do not repeat today’s date in your response.
-------------------code----------------------

Prompt
-------------------code----------------------
What time does the park close today?
-------------------code----------------------


LLM Answer
-------------------code----------------------
Wonderworld closes at 5:00 PM today.
-------------------code----------------------
Result:

* The response becomes concise and more natural for a customer support context.

---

### Step 6: Expand Business Knowledge

* The prompt can be extended with additional context:

  * Location
  * Rides
  * Ticket information
  * Policies
* More context allows the model to answer a wider range of customer questions accurately.

instructions
-------------------code----------------------
You are a customer support agent for a theme park named Wonderworld.

Wonderworld opening hours:
- Monday to Thursday: 9:00 AM to 5:00 PM
- Friday to Sunday: 9:00 AM to 9:00 PM

Today is Thursday, July 17.

Do not repeat today’s date in your response.
-------------------code----------------------

Prompt
-------------------code----------------------
What is the capital of France?
-------------------code----------------------


LLM Answer
-------------------code----------------------
The capital of France is Paris.
-------------------code----------------------

---

### Step 7: Restrict the Model’s Scope

* Problem:

  * The model answers unrelated questions, such as general knowledge queries.
* Solution:

  * Explicitly instruct the model to only answer questions related to Wonderworld.

instructions
-------------------code----------------------
You are a customer support agent for a theme park named Wonderworld.

Wonderworld opening hours:
- Monday to Thursday: 9:00 AM to 5:00 PM
- Friday to Sunday: 9:00 AM to 9:00 PM

Today is Thursday, July 17.

Only answer questions related to Wonderworld.
If the question is unrelated, respond with:
"I'm here to help with Wonderworld-related questions. Let me know if you'd like information about your visit."
-------------------code----------------------


Prompt
-------------------code----------------------
What is the capital of France?
-------------------code----------------------


LLM Answer
-------------------code----------------------
I'm here to help with Wonderworld-related questions. Let me know if you'd like information about your visit.
-------------------code----------------------

Result:

* Out-of-scope questions receive a polite, domain-specific refusal.

---

### Step 8: Handle Invalid or Unclear Input

* Test the prompt with gibberish or unclear input.
* The model responds by:

  * Acknowledging the unclear message
  * Redirecting the user back to relevant Wonderworld questions

instructions
-------------------code----------------------
You are a customer support agent for a theme park named Wonderworld.

Wonderworld opening hours:
- Monday to Thursday: 9:00 AM to 5:00 PM
- Friday to Sunday: 9:00 AM to 9:00 PM

Today is Thursday, July 17.

Only answer questions related to Wonderworld.
If the input is unclear or invalid, politely ask the user to clarify.
-------------------code----------------------


Prompt
-------------------code----------------------
asdj!@#123??
-------------------code----------------------


LLM Answer
-------------------code----------------------
It looks like your message may be unclear. If you have any questions about Wonderworld, feel free to ask and I’ll be happy to help.
-------------------code----------------------

This behavior improves robustness and user experience.


### Step 9: Final Production-Ready Prompt
instructions
-------------------code----------------------
You are a customer support assistant for a theme park named Wonderworld.

Wonderworld information:
- Opening hours:
  - Monday to Thursday: 9:00 AM to 5:00 PM
  - Friday to Sunday: 9:00 AM to 9:00 PM

Today is Thursday, July 17.

Rules:
- Only answer questions related to Wonderworld (hours, tickets, rides, location, policies).
- If the question is unrelated, respond with:
  "I'm here to help with Wonderworld-related questions. Let me know if you'd like information about your visit."
- If the input is unclear or invalid, ask the user to clarify.
- Do not repeat today’s date.
- Do not guess or invent information.
-------------------code----------------------

---

### Key Takeaways

* Prompt design is an iterative process, similar to writing and refining code.
* Start with a simple prompt and gradually add:

  * Context
  * Constraints
  * Error handling
* Continuous testing and refinement lead to more reliable and natural responses.

---

### What’s Next

* The refined prompt will be integrated into the application.
* Further improvements will be made at the chatbot level in the next lesson.

---


*** 9- Improving Chatbot Responses ***

---

## Integrating the Prompt into the Application

### Goal of the Lesson

* Bring the refined prompt from the previous lesson into the actual application.
* Improve the chatbot by separating prompt logic from business content.
* Load and inject structured park information dynamically.
* Make small UI improvements to enhance chat readability.

Directory Structure
-------------------code----------------------
server/
 ├── prompts/
 │    ├── chatbot.txt
 │    └── wonderworld.md
 ├── services/
 │    └── chat.service.ts
-------------------code----------------------
---

## Organizing Prompts in the Project

### Creating a Prompts Directory

* Inside the `server` directory, create a new folder named `prompts`.
* Purpose:

  * Keep prompt text separate from application logic.
  * Avoid embedding long instruction text directly in code.
  * Make prompts easier to maintain and refine over time.

### Creating the Prompt File

* Add a file named `chatbot.txt` inside the `prompts` directory.
* Paste the refined prompt from the previous lesson into this file.

---

## Moving Park Information to a Markdown File

### Why Use a Markdown File

* Park information is content, not instructions.
* Prompt instructions and park data are separate concerns.
* Park details may change without needing to rewrite prompt logic.
-------------------code----------------------
Markdown Preview Enhanced
-------------------code----------------------

### Adding the Markdown File

* Download the provided `wonderworld.md` file.
* Place it in the `prompts` directory.
* This file contains:

  * Ticket and pricing information
  * Park hours
  * Ride descriptions
  * Accommodation and other park services

---

## Previewing Markdown Content

* Install the VS Code extension **Markdown Preview Enhanced** by Yi Yi Wong.
* Use the preview feature to easily read and verify the park content.

---

## Updating the Prompt Structure

### Removing Hard-Coded Details
-------------------code----------------------
You're a customer support agent for a theme park named WonderWorld.

Monday - Thursday: 9am - 5pm
Friday - Sunday: 9am - 9pm

Today is Thursday, July 17. Do not repeat today's date in your response.

Only answer questions related to WonderWorld.
-------------------code----------------------

* Remove park hours from `chatbot.txt`.
* Remove references to the current date.
* Assumption:

  * The park closes at the same time every day, so no date logic is needed.

-------------------code----------------------
You're a customer support agent for a theme park named WonderWorld.

Here's some key information about the park:

{{parkInfo}}

Only answer questions related to WonderWorld.
-------------------code----------------------

### Adding a Placeholder for Park Information

* Add a section such as:

  * “Here is some key information about the park:”
* Insert a placeholder like `{{park_info}}`.
* This placeholder will be replaced dynamically at runtime.
-------------------code----------------------
You're a customer support agent for a theme park named WonderWorld.

Here's some key information about the park:

{{parkInfo}}

Only answer questions related to WonderWorld.
-------------------code----------------------

### Refining Prompt Instructions

* Restrict answers to Wonderworld-related questions only.
* Add behavioral guidance:

  * Always respond in a cheerful tone.
  * Avoid making up information.
* The prompt now focuses purely on:

  * Role definition
  * Scope
  * Tone
  * Safety constraints

-------------------code----------------------
You're a customer support agent for a theme park named WonderWorld.

Here's some key information about the park:

{{parkInfo}}

Only answer questions related to WonderWorld.
Always answer in a cheerful tone and avoid making up information.
-------------------code----------------------
---

## Loading Prompt and Markdown Files in Code

### Importing the Prompt Template

* Import `chatbot.txt` into the chat service.
* Name it `template` to reflect its role as a reusable prompt template.

### Reading the Markdown File

* Markdown files cannot be imported directly.
* Use Node.js modules:

  * `fs` for file reading
  * `path` for building file paths
-------------------code----------------------
import fs from "fs";
import path from "path";
import template from "../prompts/chatbot.txt";
-------------------code----------------------

### Reading the File

* Use synchronous file reading to load the park information once.
* Build the path using:

  * Current directory
  * One level up
  * `prompts` directory
  * `wonderworld.md`
* Read the file using UTF-8 encoding.
-------------------code----------------------
const parkInfoPath = path.join(__dirname, "..", "prompts", "wonderworld.md");
const parkInfo = fs.readFileSync(parkInfoPath, "utf8");
const instructions = template.replace("{{parkInfo}}", parkInfo);
-------------------code----------------------
---

## Injecting Park Information into the Prompt

* Replace the placeholder in the prompt template with the markdown content.
* This produces the final instruction text sent to the model.
* This replacement happens once when the module is loaded.
* The same prompt is reused for every API request.

---

## Testing the Updated Chatbot

### Initial Behavior

* The chatbot greets the user with a Wonderworld-specific welcome message.
* Confirms that the prompt and park data are loaded correctly.

### Example Questions

* Park closing time:

  * The chatbot responds correctly.
* Hotel availability:

  * The chatbot provides accurate accommodation details.
* Irrelevant questions:

  * The chatbot politely redirects the user back to Wonderworld topics.

Result:

* The chatbot is now domain-aware, polite, and controlled.

---

## UI Improvement: Message Width

### Problem

* Chat messages are too wide.
* Long line lengths reduce readability.

### Solution

* Update the chat message component.
* Apply a maximum width (e.g., medium size).
* This results in:

  * Shorter line lengths
  * Better readability
  * A more natural chat appearance
-------------------code----------------------
<div
    key={index}
    ref={index === messages.length - 1 ? lastMessageRef : null}
    onCopy={onCopyMessage}
    className={`
      px-3 py-1 rounded-xl max-w-md 
      ${
        message.role === "user"
          ? "bg-blue-600 text-white self-end"
          : "bg-gray-100 text-black self-start"
      }
    `}
  >
-------------------code----------------------
---

## Key Takeaways

* Prompts should live outside application logic.
* Instructions and business data should be kept separate.
* Markdown is a clean way to store structured knowledge.
* Prompt assembly should happen once and be reused.
* Small UI changes can significantly improve user experience.

---
